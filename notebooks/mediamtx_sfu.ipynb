{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ColaStream - WebRTC SFU on Google Colab\n",
    "\n",
    "Run a WebRTC SFU server on Colab for AI-powered live streaming.\n",
    "\n",
    "**Features:**\n",
    "- WHIP/WHEP WebRTC streaming\n",
    "- Works behind Colab's NAT via TURN relay\n",
    "- Publish from OBS, browser, or any WHIP client\n",
    "- Process video frames with AI in real-time\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Install MediaMTX and required dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install MediaMTX { display-mode: \"form\" }\n",
    "#@markdown Downloads and extracts MediaMTX SFU server\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "MEDIAMTX_VERSION = \"v1.9.3\"\n",
    "MEDIAMTX_URL = f\"https://github.com/bluenviron/mediamtx/releases/download/{MEDIAMTX_VERSION}/mediamtx_{MEDIAMTX_VERSION}_linux_amd64.tar.gz\"\n",
    "\n",
    "# Download and extract\n",
    "!wget -q {MEDIAMTX_URL} -O mediamtx.tar.gz\n",
    "!tar -xzf mediamtx.tar.gz\n",
    "!chmod +x mediamtx\n",
    "!rm mediamtx.tar.gz\n",
    "\n",
    "print(f\"MediaMTX {MEDIAMTX_VERSION} installed!\")\n",
    "!./mediamtx --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title Install Cloudflared (No account needed) { display-mode: \"form\" }\n#@markdown Downloads cloudflared for tunneling - no signup required!\n\n!wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O cloudflared\n!chmod +x cloudflared\nprint(\"cloudflared installed!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure MediaMTX\n",
    "\n",
    "Create a configuration optimized for Colab's network environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title Configure MediaMTX for Colab { display-mode: \"form\" }\n#@markdown Automatically fetches TURN servers from VDO.Ninja\n\nimport requests\nimport json\n\n#@markdown ---\n#@markdown **Stream Settings**\ndefault_stream_name = \"live\" #@param {type:\"string\"}\n\n# Fetch TURN servers from VDO.Ninja\nprint(\"Fetching TURN servers from VDO.Ninja...\")\ntry:\n    r = requests.get(\"https://turnservers.vdo.ninja/\", timeout=10)\n    turn_data = r.json()\n    turn_servers = turn_data.get(\"servers\", [])\n    print(f\"Got {len(turn_servers)} TURN servers!\")\nexcept Exception as e:\n    print(f\"Warning: Could not fetch TURN servers: {e}\")\n    print(\"Using fallback servers...\")\n    turn_servers = [\n        {\"urls\": [\"turn:turn-use1.vdo.ninja:3478\"], \"username\": \"vdoninja\", \"credential\": \"EastSideRepresentZ\"},\n        {\"urls\": [\"turn:turn-use2.vdo.ninja:3478\"], \"username\": \"vdoninja\", \"credential\": \"pleaseUseYourOwn\"},\n    ]\n\n# Build ICE servers YAML\nice_servers_yaml = \"  - url: stun:stun.l.google.com:19302\\n\"\nfor server in turn_servers:\n    urls = server.get(\"urls\", [])\n    username = server.get(\"username\", \"\")\n    credential = server.get(\"credential\", \"\")\n    for url in urls:\n        ice_servers_yaml += f\"  - url: {url}\\n\"\n        ice_servers_yaml += f\"    username: {username}\\n\"\n        ice_servers_yaml += f\"    password: {credential}\\n\"\n\nconfig = f\"\"\"\n###############################################\n# MediaMTX Configuration for Google Colab\n# TURN servers from: https://turnservers.vdo.ninja/\n###############################################\n\n# Logging\nlogLevel: info\nlogDestinations: [stdout]\n\n# API (for status checks)\napi: yes\napiAddress: 127.0.0.1:9997\n\n# RTSP Server (internal use)\nrtsp: yes\nrtspAddress: :8554\nprotocols: [tcp]  # TCP only for Colab compatibility\n\n# HLS Server (fallback playback)\nhls: yes\nhlsAddress: :8888\nhlsAlwaysRemux: yes\n\n# WebRTC Server\nwebrtc: yes\nwebrtcAddress: :8889\n\n# ICE Configuration - Critical for Colab!\n# VDO.Ninja TURN servers for reliable connectivity\nwebrtcICEServers2:\n{ice_servers_yaml}\n# Force TCP candidates only (UDP usually blocked on Colab)\nwebrtcICEHostNAT1To1IPs: []\nwebrtcICEUDPMuxAddress:\nwebrtcICETCPMuxAddress: :8189\n\n# Path configuration\npaths:\n  all_others:\n\"\"\"\n\nwith open(\"mediamtx.yml\", \"w\") as f:\n    f.write(config)\n\nprint(\"\\nConfiguration saved to mediamtx.yml\")\nprint(f\"Default stream path: /{default_stream_name}\")\nprint(\"\\nTURN servers configured:\")\nfor server in turn_servers[:3]:  # Show first 3\n    print(f\"  - {server.get('urls', ['?'])[0]}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Start the Server\n",
    "\n",
    "Launch MediaMTX and create a public tunnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Start MediaMTX Server { display-mode: \"form\" }\n",
    "#@markdown Starts MediaMTX in the background\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Kill any existing instance\n",
    "!pkill -f mediamtx 2>/dev/null || true\n",
    "time.sleep(1)\n",
    "\n",
    "# Start MediaMTX in background\n",
    "process = subprocess.Popen(\n",
    "    [\"./mediamtx\", \"mediamtx.yml\"],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT\n",
    ")\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "# Check if running\n",
    "if process.poll() is None:\n",
    "    print(\"MediaMTX is running!\")\n",
    "    print(\"\\nLocal endpoints:\")\n",
    "    print(\"  - WebRTC (WHIP/WHEP): http://localhost:8889\")\n",
    "    print(\"  - HLS: http://localhost:8888\")\n",
    "    print(\"  - RTSP: rtsp://localhost:8554\")\n",
    "    print(\"  - API: http://localhost:9997\")\n",
    "else:\n",
    "    print(\"Failed to start MediaMTX!\")\n",
    "    print(process.stdout.read().decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title Alternative: ngrok Tunnel (requires free account) { display-mode: \"form\" }\n#@markdown Use this if cloudflared isn't working. Requires ngrok signup.\n\n#@markdown Get your free authtoken at: https://dashboard.ngrok.com/get-started/your-authtoken\nngrok_authtoken = \"\" #@param {type:\"string\"}\nstream_name = \"live\" #@param {type:\"string\"}\n\nif not ngrok_authtoken:\n    print(\"ERROR: ngrok now requires authentication.\")\n    print(\"1. Sign up free at: https://dashboard.ngrok.com/signup\")\n    print(\"2. Get your authtoken: https://dashboard.ngrok.com/get-started/your-authtoken\")\n    print(\"3. Paste it above and run this cell again\")\n    print(\"\\nOr use the Cloudflared tunnel instead (no account needed)!\")\nelse:\n    !pip install -q pyngrok\n    from pyngrok import ngrok\n    from urllib.parse import quote\n    \n    ngrok.set_auth_token(ngrok_authtoken)\n    ngrok.kill()\n    \n    import time\n    time.sleep(1)\n    \n    tunnel = ngrok.connect(8889, \"http\")\n    PUBLIC_URL = tunnel.public_url.replace(\"http://\", \"https://\")\n    \n    GITHUB_PAGES_URL = \"https://steveseguin.github.io/colastream\"\n    publish_url = f\"{GITHUB_PAGES_URL}/?server={quote(PUBLIC_URL)}&stream={quote(stream_name)}\"\n    watch_url = f\"{GITHUB_PAGES_URL}/watch.html?server={quote(PUBLIC_URL)}&stream={quote(stream_name)}\"\n    \n    print(\"=\" * 70)\n    print(\"NGROK TUNNEL ACTIVE!\")\n    print(\"=\" * 70)\n    print(f\"\\nServer URL: {PUBLIC_URL}\")\n    print(f\"\\nPublish from browser:\\n  {publish_url}\")\n    print(f\"\\nShare this link for viewers:\\n  {watch_url}\")\n    print(\"=\" * 70)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title Create Public Tunnel (Cloudflared) { display-mode: \"form\" }\n#@markdown Creates a public HTTPS URL for your MediaMTX server (no account needed!)\n\nimport subprocess\nimport re\nimport time\nfrom urllib.parse import quote\n\nstream_name = \"live\" #@param {type:\"string\"}\n\n# GitHub Pages base URL (update this to your repo)\nGITHUB_PAGES_URL = \"https://steveseguin.github.io/colastream\"\n\n# Start cloudflared\nprocess = subprocess.Popen(\n    [\"./cloudflared\", \"tunnel\", \"--url\", \"http://localhost:8889\"],\n    stdout=subprocess.PIPE,\n    stderr=subprocess.STDOUT\n)\n\nprint(\"Starting cloudflared tunnel...\")\nprint(\"(This may take 10-20 seconds)\\n\")\n\n# Wait for URL\nPUBLIC_URL = None\nfor _ in range(30):\n    line = process.stdout.readline().decode()\n    if \"trycloudflare.com\" in line:\n        match = re.search(r'https://[a-z0-9-]+\\.trycloudflare\\.com', line)\n        if match:\n            PUBLIC_URL = match.group(0)\n            break\n    time.sleep(1)\n\nif PUBLIC_URL:\n    print(\"=\" * 70)\n    print(\"TUNNEL ACTIVE!\")\n    print(\"=\" * 70)\n    print(f\"\\nServer URL: {PUBLIC_URL}\")\n    print(f\"\\nWHIP endpoint: {PUBLIC_URL}/{stream_name}/whip\")\n    print(f\"WHEP endpoint: {PUBLIC_URL}/{stream_name}/whep\")\n    \n    # Generate GitHub Pages links\n    publish_url = f\"{GITHUB_PAGES_URL}/?server={quote(PUBLIC_URL)}&stream={quote(stream_name)}\"\n    watch_url = f\"{GITHUB_PAGES_URL}/watch.html?server={quote(PUBLIC_URL)}&stream={quote(stream_name)}\"\n    \n    print(\"\\n\" + \"=\" * 70)\n    print(\"WEB INTERFACE (with webcam selector)\")\n    print(\"=\" * 70)\n    print(f\"\\nPublish from browser:\")\n    print(f\"  {publish_url}\")\n    print(f\"\\nShare this link for viewers:\")\n    print(f\"  {watch_url}\")\n    print(\"\\n\" + \"=\" * 70)\nelse:\n    print(\"ERROR: Timeout waiting for tunnel URL\")\n    print(\"Try running this cell again.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the Stream\n",
    "\n",
    "Use the built-in test client or connect from OBS/browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Browser Test Client { display-mode: \"form\" }\n",
    "#@markdown Displays an embedded WHIP/WHEP test interface\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "# Get the public URL (use a placeholder if not set)\n",
    "try:\n",
    "    base_url = PUBLIC_URL\n",
    "except:\n",
    "    base_url = \"YOUR_TUNNEL_URL\"\n",
    "\n",
    "html_content = f\"\"\"\n",
    "<style>\n",
    "    .colastream-container {{\n",
    "        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;\n",
    "        max-width: 800px;\n",
    "        padding: 20px;\n",
    "        background: #1a1a2e;\n",
    "        border-radius: 12px;\n",
    "        color: #eee;\n",
    "    }}\n",
    "    .colastream-container h3 {{\n",
    "        color: #00d4ff;\n",
    "        margin-top: 0;\n",
    "    }}\n",
    "    .colastream-container input, .colastream-container button {{\n",
    "        padding: 10px 15px;\n",
    "        margin: 5px;\n",
    "        border-radius: 6px;\n",
    "        border: none;\n",
    "        font-size: 14px;\n",
    "    }}\n",
    "    .colastream-container input {{\n",
    "        background: #16213e;\n",
    "        color: #fff;\n",
    "        width: 300px;\n",
    "    }}\n",
    "    .colastream-container button {{\n",
    "        background: #00d4ff;\n",
    "        color: #000;\n",
    "        cursor: pointer;\n",
    "        font-weight: bold;\n",
    "    }}\n",
    "    .colastream-container button:hover {{\n",
    "        background: #00a8cc;\n",
    "    }}\n",
    "    .colastream-container button.stop {{\n",
    "        background: #ff4757;\n",
    "    }}\n",
    "    .colastream-container video {{\n",
    "        width: 100%;\n",
    "        max-width: 640px;\n",
    "        background: #000;\n",
    "        border-radius: 8px;\n",
    "        margin: 10px 0;\n",
    "    }}\n",
    "    .colastream-container .status {{\n",
    "        padding: 8px 12px;\n",
    "        background: #16213e;\n",
    "        border-radius: 6px;\n",
    "        margin: 10px 0;\n",
    "        font-family: monospace;\n",
    "    }}\n",
    "    .colastream-container .section {{\n",
    "        margin: 20px 0;\n",
    "        padding: 15px;\n",
    "        background: #16213e;\n",
    "        border-radius: 8px;\n",
    "    }}\n",
    "</style>\n",
    "\n",
    "<div class=\"colastream-container\">\n",
    "    <h3>ColaStream WebRTC Test Client</h3>\n",
    "    \n",
    "    <div class=\"section\">\n",
    "        <strong>Server URL:</strong><br>\n",
    "        <input type=\"text\" id=\"serverUrl\" value=\"{base_url}\" style=\"width: 400px;\">\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"section\">\n",
    "        <strong>Publish Stream (WHIP)</strong><br>\n",
    "        <input type=\"text\" id=\"publishPath\" value=\"live\" placeholder=\"Stream name\">\n",
    "        <button onclick=\"startPublish()\">Start Publishing</button>\n",
    "        <button onclick=\"stopPublish()\" class=\"stop\">Stop</button>\n",
    "        <div class=\"status\" id=\"publishStatus\">Not publishing</div>\n",
    "        <video id=\"localVideo\" autoplay muted playsinline></video>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"section\">\n",
    "        <strong>Watch Stream (WHEP)</strong><br>\n",
    "        <input type=\"text\" id=\"watchPath\" value=\"live\" placeholder=\"Stream name\">\n",
    "        <button onclick=\"startWatch()\">Start Watching</button>\n",
    "        <button onclick=\"stopWatch()\" class=\"stop\">Stop</button>\n",
    "        <div class=\"status\" id=\"watchStatus\">Not watching</div>\n",
    "        <video id=\"remoteVideo\" autoplay playsinline></video>\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<script>\n",
    "let publishPc = null;\n",
    "let watchPc = null;\n",
    "let localStream = null;\n",
    "\n",
    "async function startPublish() {{\n",
    "    const serverUrl = document.getElementById('serverUrl').value;\n",
    "    const path = document.getElementById('publishPath').value;\n",
    "    const status = document.getElementById('publishStatus');\n",
    "    \n",
    "    try {{\n",
    "        status.textContent = 'Requesting camera access...';\n",
    "        localStream = await navigator.mediaDevices.getUserMedia({{video: true, audio: true}});\n",
    "        document.getElementById('localVideo').srcObject = localStream;\n",
    "        \n",
    "        status.textContent = 'Creating WebRTC connection...';\n",
    "        publishPc = new RTCPeerConnection({{\n",
    "            iceServers: [\n",
    "                {{ urls: 'stun:stun.l.google.com:19302' }}\n",
    "            ]\n",
    "        }});\n",
    "        \n",
    "        localStream.getTracks().forEach(track => publishPc.addTrack(track, localStream));\n",
    "        \n",
    "        const offer = await publishPc.createOffer();\n",
    "        await publishPc.setLocalDescription(offer);\n",
    "        \n",
    "        status.textContent = 'Sending offer to server...';\n",
    "        const response = await fetch(`${{serverUrl}}/${{path}}/whip`, {{\n",
    "            method: 'POST',\n",
    "            headers: {{ 'Content-Type': 'application/sdp' }},\n",
    "            body: offer.sdp\n",
    "        }});\n",
    "        \n",
    "        if (!response.ok) throw new Error(`Server error: ${{response.status}}`);\n",
    "        \n",
    "        const answer = await response.text();\n",
    "        await publishPc.setRemoteDescription({{ type: 'answer', sdp: answer }});\n",
    "        \n",
    "        status.textContent = 'Publishing to: ' + path;\n",
    "        status.style.color = '#00ff88';\n",
    "    }} catch (e) {{\n",
    "        status.textContent = 'Error: ' + e.message;\n",
    "        status.style.color = '#ff4757';\n",
    "        console.error(e);\n",
    "    }}\n",
    "}}\n",
    "\n",
    "function stopPublish() {{\n",
    "    if (publishPc) {{ publishPc.close(); publishPc = null; }}\n",
    "    if (localStream) {{ localStream.getTracks().forEach(t => t.stop()); localStream = null; }}\n",
    "    document.getElementById('localVideo').srcObject = null;\n",
    "    document.getElementById('publishStatus').textContent = 'Stopped';\n",
    "    document.getElementById('publishStatus').style.color = '#eee';\n",
    "}}\n",
    "\n",
    "async function startWatch() {{\n",
    "    const serverUrl = document.getElementById('serverUrl').value;\n",
    "    const path = document.getElementById('watchPath').value;\n",
    "    const status = document.getElementById('watchStatus');\n",
    "    \n",
    "    try {{\n",
    "        status.textContent = 'Creating WebRTC connection...';\n",
    "        watchPc = new RTCPeerConnection({{\n",
    "            iceServers: [\n",
    "                {{ urls: 'stun:stun.l.google.com:19302' }}\n",
    "            ]\n",
    "        }});\n",
    "        \n",
    "        watchPc.ontrack = (e) => {{\n",
    "            document.getElementById('remoteVideo').srcObject = e.streams[0];\n",
    "        }};\n",
    "        \n",
    "        watchPc.addTransceiver('video', {{ direction: 'recvonly' }});\n",
    "        watchPc.addTransceiver('audio', {{ direction: 'recvonly' }});\n",
    "        \n",
    "        const offer = await watchPc.createOffer();\n",
    "        await watchPc.setLocalDescription(offer);\n",
    "        \n",
    "        status.textContent = 'Connecting to stream...';\n",
    "        const response = await fetch(`${{serverUrl}}/${{path}}/whep`, {{\n",
    "            method: 'POST',\n",
    "            headers: {{ 'Content-Type': 'application/sdp' }},\n",
    "            body: offer.sdp\n",
    "        }});\n",
    "        \n",
    "        if (!response.ok) throw new Error(`Server error: ${{response.status}}`);\n",
    "        \n",
    "        const answer = await response.text();\n",
    "        await watchPc.setRemoteDescription({{ type: 'answer', sdp: answer }});\n",
    "        \n",
    "        status.textContent = 'Watching: ' + path;\n",
    "        status.style.color = '#00ff88';\n",
    "    }} catch (e) {{\n",
    "        status.textContent = 'Error: ' + e.message;\n",
    "        status.style.color = '#ff4757';\n",
    "        console.error(e);\n",
    "    }}\n",
    "}}\n",
    "\n",
    "function stopWatch() {{\n",
    "    if (watchPc) {{ watchPc.close(); watchPc = null; }}\n",
    "    document.getElementById('remoteVideo').srcObject = null;\n",
    "    document.getElementById('watchStatus').textContent = 'Stopped';\n",
    "    document.getElementById('watchStatus').style.color = '#eee';\n",
    "}}\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. OBS Studio Setup\n",
    "\n",
    "To publish from OBS Studio 30+:\n",
    "\n",
    "1. Go to **Settings > Stream**\n",
    "2. Set **Service** to \"WHIP\"\n",
    "3. Set **Server** to: `YOUR_TUNNEL_URL/live/whip`\n",
    "4. Leave **Bearer Token** empty\n",
    "5. Click **Start Streaming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Show OBS Settings { display-mode: \"form\" }\n",
    "\n",
    "try:\n",
    "    url = PUBLIC_URL\n",
    "except:\n",
    "    url = \"YOUR_TUNNEL_URL\"\n",
    "\n",
    "print(\"OBS Studio WHIP Settings\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Service: WHIP\")\n",
    "print(f\"Server:  {url}/live/whip\")\n",
    "print(f\"Bearer Token: (leave empty)\")\n",
    "print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. AI Video Processing\n",
    "\n",
    "Connect to the RTSP stream for frame-by-frame AI processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install OpenCV { display-mode: \"form\" }\n",
    "!pip install -q opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title AI Frame Processor Example { display-mode: \"form\" }\n",
    "#@markdown Process video frames from the MediaMTX stream\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "import PIL.Image\n",
    "import time\n",
    "\n",
    "stream_name = \"live\" #@param {type:\"string\"}\n",
    "process_frames = 30 #@param {type:\"integer\"}\n",
    "\n",
    "# Connect to local RTSP stream\n",
    "rtsp_url = f\"rtsp://localhost:8554/{stream_name}\"\n",
    "print(f\"Connecting to: {rtsp_url}\")\n",
    "\n",
    "cap = cv2.VideoCapture(rtsp_url)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Could not connect to stream. Make sure:\")\n",
    "    print(\"1. MediaMTX is running\")\n",
    "    print(\"2. Someone is publishing to the stream\")\n",
    "else:\n",
    "    print(f\"Connected! Processing {process_frames} frames...\\n\")\n",
    "    \n",
    "    for i in range(process_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Stream ended or error\")\n",
    "            break\n",
    "        \n",
    "        # === YOUR AI PROCESSING HERE ===\n",
    "        # Example: Convert to grayscale edge detection\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        edges = cv2.Canny(gray, 100, 200)\n",
    "        \n",
    "        # Convert back to color for display\n",
    "        processed = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n",
    "        # ================================\n",
    "        \n",
    "        # Display every 5th frame\n",
    "        if i % 5 == 0:\n",
    "            clear_output(wait=True)\n",
    "            img = PIL.Image.fromarray(processed)\n",
    "            display(img)\n",
    "            print(f\"Frame {i+1}/{process_frames}\")\n",
    "    \n",
    "    cap.release()\n",
    "    print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title YOLO Object Detection Example { display-mode: \"form\" }\n",
    "#@markdown Real-time object detection on the stream\n",
    "\n",
    "!pip install -q ultralytics\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from IPython.display import display, clear_output\n",
    "import PIL.Image\n",
    "\n",
    "stream_name = \"live\" #@param {type:\"string\"}\n",
    "process_frames = 30 #@param {type:\"integer\"}\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO('yolov8n.pt')  # nano model for speed\n",
    "\n",
    "# Connect to stream\n",
    "cap = cv2.VideoCapture(f\"rtsp://localhost:8554/{stream_name}\")\n",
    "\n",
    "if cap.isOpened():\n",
    "    for i in range(process_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Run YOLO inference\n",
    "        results = model(frame, verbose=False)\n",
    "        \n",
    "        # Draw detections\n",
    "        annotated = results[0].plot()\n",
    "        \n",
    "        # Display\n",
    "        if i % 3 == 0:\n",
    "            clear_output(wait=True)\n",
    "            img = PIL.Image.fromarray(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
    "            display(img)\n",
    "            \n",
    "            # Show detections\n",
    "            for r in results:\n",
    "                for box in r.boxes:\n",
    "                    cls = int(box.cls[0])\n",
    "                    conf = float(box.conf[0])\n",
    "                    name = model.names[cls]\n",
    "                    print(f\"Detected: {name} ({conf:.2f})\")\n",
    "    \n",
    "    cap.release()\n",
    "else:\n",
    "    print(\"Could not connect to stream\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Monitoring & Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Check Server Status { display-mode: \"form\" }\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "try:\n",
    "    # Get paths (streams)\n",
    "    r = requests.get(\"http://localhost:9997/v3/paths/list\")\n",
    "    data = r.json()\n",
    "    \n",
    "    print(\"Active Streams:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    if data.get(\"items\"):\n",
    "        for item in data[\"items\"]:\n",
    "            name = item.get(\"name\", \"unknown\")\n",
    "            ready = item.get(\"ready\", False)\n",
    "            readers = item.get(\"readers\", [])\n",
    "            \n",
    "            status = \"LIVE\" if ready else \"waiting\"\n",
    "            print(f\"  /{name}: {status} ({len(readers)} viewers)\")\n",
    "    else:\n",
    "        print(\"  No active streams\")\n",
    "    \n",
    "    print(\"=\" * 40)\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to API: {e}\")\n",
    "    print(\"Is MediaMTX running?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title View MediaMTX Logs { display-mode: \"form\" }\n",
    "!ps aux | grep mediamtx | grep -v grep || echo \"MediaMTX not running\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Restart MediaMTX { display-mode: \"form\" }\n",
    "!pkill -f mediamtx 2>/dev/null || true\n",
    "import time\n",
    "time.sleep(2)\n",
    "\n",
    "import subprocess\n",
    "process = subprocess.Popen([\"./mediamtx\", \"mediamtx.yml\"], \n",
    "                          stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "time.sleep(3)\n",
    "\n",
    "if process.poll() is None:\n",
    "    print(\"MediaMTX restarted successfully!\")\n",
    "else:\n",
    "    print(\"Failed to restart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. VDO.Ninja P2P Mode (No Tunnel Required!)\n\nAs an alternative to MediaMTX + cloudflared, you can use VDO.Ninja's P2P infrastructure directly. This eliminates the need for any tunneling!\n\n**Workflow:**\n1. Open the ColaStream publish page in your browser\n2. Copy the Stream ID\n3. Receive the stream in Colab via VDO.Ninja"
  },
  {
   "cell_type": "code",
   "source": "#@title Receive VDO.Ninja Stream { display-mode: \"form\" }\n#@markdown Receive video from a VDO.Ninja stream using Selenium\n\n#@markdown 1. First, publish from: https://steveseguin.github.io/colastream/publish.html\n#@markdown 2. Copy your Stream ID below\n\nstream_id = \"YOUR_STREAM_ID\" #@param {type:\"string\"}\nprocess_frames = 30 #@param {type:\"integer\"}\n\n# Install dependencies\n!pip install -q selenium webdriver-manager opencv-python-headless pillow\n\nimport time\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.options import Options\nfrom selenium.webdriver.chrome.service import Service\nfrom webdriver_manager.chrome import ChromeDriverManager\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom IPython.display import display, clear_output\nimport base64\n\n# Setup headless Chrome\nchrome_options = Options()\nchrome_options.add_argument(\"--headless\")\nchrome_options.add_argument(\"--no-sandbox\")\nchrome_options.add_argument(\"--disable-dev-shm-usage\")\nchrome_options.add_argument(\"--disable-gpu\")\nchrome_options.add_argument(\"--window-size=1280,720\")\n\nprint(\"Starting headless browser...\")\ndriver = webdriver.Chrome(\n    service=Service(ChromeDriverManager().install()),\n    options=chrome_options\n)\n\n# Navigate to VDO.Ninja view URL\nvdo_url = f\"https://vdo.ninja/?view={stream_id}&autostart\"\nprint(f\"Connecting to: {vdo_url}\")\ndriver.get(vdo_url)\n\n# Wait for video to load\nprint(\"Waiting for stream...\")\ntime.sleep(8)\n\n# Find video element\ntry:\n    video = driver.find_element(\"tag name\", \"video\")\n    print(f\"Video found! Processing {process_frames} frames...\\n\")\n    \n    for i in range(process_frames):\n        # Capture frame from video using canvas\n        frame_data = driver.execute_script(\"\"\"\n            var video = document.querySelector('video');\n            if (!video || video.readyState < 2) return null;\n            var canvas = document.createElement('canvas');\n            canvas.width = video.videoWidth || 640;\n            canvas.height = video.videoHeight || 480;\n            canvas.getContext('2d').drawImage(video, 0, 0);\n            return canvas.toDataURL('image/jpeg', 0.8);\n        \"\"\")\n        \n        if frame_data and frame_data.startswith('data:image'):\n            # Decode base64 image\n            img_data = base64.b64decode(frame_data.split(',')[1])\n            img_array = np.frombuffer(img_data, dtype=np.uint8)\n            frame = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n            \n            if frame is not None:\n                # === YOUR AI PROCESSING HERE ===\n                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n                edges = cv2.Canny(gray, 100, 200)\n                processed = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n                # ================================\n                \n                # Display\n                if i % 3 == 0:\n                    clear_output(wait=True)\n                    img = Image.fromarray(cv2.cvtColor(processed, cv2.COLOR_BGR2RGB))\n                    display(img)\n                    print(f\"Frame {i+1}/{process_frames} - {frame.shape[1]}x{frame.shape[0]}\")\n        \n        time.sleep(0.1)  # ~10 fps capture rate\n    \n    print(\"\\nDone!\")\n\nexcept Exception as e:\n    print(f\"Error: {e}\")\n    print(\"Make sure someone is publishing to the stream ID\")\n\nfinally:\n    driver.quit()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}